# Azure Storage Account Defender Malware Scanning

A function that wraps Azure Storage Malware scanning into a simple API.

Scanned blobs are subject to a lifetime policy that deletes them after 3 days.

```azd up -t AzureStorageMalwareScanning```

```curl -F "testfile=@/home/graeme/pictures/test.jpg" -H "x-functions-key=<function-code>" https://myfunction.azurewebsites.net/api/scan```

```json
{
    "result":"No threats found",
    "scanResult":"Ok",
    "fileName":"file1.txt",
    "id":"28dc03ef-67f2-43af-afe3-cea47b16db6e",
    "scanMs":8344
}
```

## Permissions

Writing blobs requires the ```Microsoft.Storage/storageAccounts/blobServices/containers/blobs/add/action``` and the ```Microsoft.Storage/storageAccounts/blobServices/containers/blobs/write``` permissions. See [https://learn.microsoft.com/en-us/rest/api/storageservices/put-blob?tabs=azure-ad](https://learn.microsoft.com/en-us/rest/api/storageservices/put-blob?tabs=azure-ad) for more details.

> The least privileged built-in-role with this is ```Storage Blob Data Contributor```

Reading the Defender Malware scanning Blob tags requires the ```Microsoft.Storage/storageAccounts/blobServices/containers/blobs/tags/read``` permissions. See [https://learn.microsoft.com/en-us/rest/api/storageservices/get-blob-tags?tabs=azure-ad](https://learn.microsoft.com/en-us/rest/api/storageservices/get-blob-tags?tabs=azure-ad) for more details. 

> The least privileged built-in-role with this is ```Storage Blob Data Owner```

## Observed timings

NB: these are purely my own observed experience.

| File Size | File Type | Observed Latency |
| -- | -- | --|
| 400kb | jpg | 8 - 10 seconds 
| 80kb | png | 6 - 8 seconds
| 2.5Mb| pdf | 8 - 10 seconds 

## Architecture

![Architecture Diagram showing functions and flows](./assets/Azure%20Defender%20file%20scanning%20-%20Monitor%20metadata.drawio.png)

All flows from the function app to the storage account auth using a System Assigned Managed Identity.

## Limitations

This architecture is intended for smaller files (<50 MB). If you are streaming extremely large files then consider an approach that adds resiliency and performance the file upload to storage.
